# -*- coding: utf-8 -*-
"""00_pytorch_fundamentals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HxueSvgIF5rLiI4chKzqIZ_H0Grz518H

## 00. PyTorch Fundamentals
"""

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
print(torch.__version__)

"""## Introduction to Tensors
Tensor: is a way to represent data

### Creating tensors
They are created with "torch.tensor()"
"""

# scalar
scalar=torch.tensor(7)
scalar

scalar.ndim

# Get tensor back as Python int
scalar.item()

# Vector
vector=torch.tensor([7,7])
vector

# Dimension: number of square brackets
vector.ndim

# Size
vector.shape

# Matrix
matrix=torch.tensor([[7,8],[9,10]])
matrix

matrix.ndim

matrix[1]

matrix.shape

# TENSOR
tensor=torch.tensor([[[1,2,3],
                      [3,6,9],
                      [2,4,5]]])
tensor

tensor.ndim

tensor.shape
# this means that we have 1 3x3 matrix

tensor[0]

"""# More practice with tensors

### Create a tensor of size [1,2,1]
"""

tensor121=torch.tensor([[[1],
                         [2]]])
tensor121

tensor121.ndim

tensor121.shape

"""### Create a matrix 4x2

"""

matrix42=torch.tensor([[1,1],[0,0],[2,2],[3,3]])
matrix42

matrix42.ndim

matrix42.shape

"""# Random tensors

Many neural networks learn based on initial tensors full of random numbers and then adjust those random numbers to better represent the patterns between data
"""

# Create a random tensor of size (3,4)
random_tensor=torch.rand(3,4)
random_tensor

random_tensor.ndim

# Create a random tensor of size (2,2,2)
random_tensor2=torch.rand(2,2,2)
random_tensor2

# Create a number tensor with a similar shape to an image tensor
random_image_size_tensor=torch.rand(3,224,224)
random_image_size_tensor.ndim,random_image_size_tensor.shape

"""### Zeros and Ones"""

# Create a tensor of all zeros
zeros=torch.zeros(size=(3,4))
zeros

zeros*random_tensor

# Create a tensor of all ones
ones=torch.ones(size=(3,4))
ones

ones.dtype

"""### Create a range of tensors and tensors-like"""

# Create a range
zero_to_ten=torch.arange(0,11)
zero_to_ten

zero_to_ten.ndim

# Other method with a step size
zero_to_ten=torch.arange(start=0,end=11,step=1)
zero_to_ten

# Create tensors like : create a tensor with the shape equal to an other one
ten_zeros = torch.zeros_like(zero_to_ten)
ten_zeros

"""### Tensor datatypes

**Note:** Tensor datatypes is one of the 3 big errors in PyTorch:

1. Tensors not right datatypes
2. Tensors not right shape
3. Tensors not on the right device
"""

# Float 32 tensor
float_32_tensor=torch.tensor([3.0,6.0,9.0],
                             dtype=None, #datatype
                             device=None,# what device is your tensor on
                             requires_grad=False) #whether or not to track gradients with the tensors operation


float_32_tensor

float_16_tensor=float_32_tensor.type(torch.float16)
float_16_tensor

float_16_tensor*float_32_tensor

int_32_tensor=torch.tensor([3,6,9],dtype=torch.int32)
int_32_tensor

float_32_tensor*int_32_tensor

"""### Getting information from tensors"""

# Create a tensor
some_tensor=torch.rand(3,4)
some_tensor

# Find out details about some tensor
print(some_tensor)
print(f"Datatype of tensor: {some_tensor.dtype}")
print(f"Shape of tensor: {some_tensor.shape}")
print(f"Device tensor is on: {some_tensor.device}")

"""### Manipulating Tensors (Tensor Operations)

Tensor operations include:
* Addition
* Subtraction
* Multiplication 
* Division
* Matrix multiplication
"""

# Create a tensor and add 10 to it
tensor= torch.tensor([1,2,3])
tensor+10

# Multiply tensor by 10
tensor*10

# Subtract 10
tensor-10

# Try out PyTorch in-built functions (in general use above command)
torch.mul(tensor,10)

# Element wise multiplication
tensor*tensor

# Matrix multiplication
torch.matmul(tensor,tensor)

tensor_A=torch.tensor([[1,2],
                       [3,4],
                       [5,6]])

tensor_B=torch.tensor([[7,10],
                       [8,11],
                       [9,12]])

torch.matmul(tensor_A,tensor_B)

# Transpose of a tensor
tensor_B.T

torch.matmul(tensor_A,tensor_B.T)

"""### Finding the min,max,mean,sum,etc (Tensor aggregation)"""

# Create a tensor
x=torch.arange(0,100,10)
x

x.min(), x.max()

x.mean()
x.dtype

"""### To compute the mean, the floating 32 bit datatype is needed"""

x.mean(dtype=torch.float32), x.type(torch.float32).mean()

# Find the sum
x.sum()

"""### Finding the positional min and max : use argmin() and argmax()


"""

x

# Find the position in tensor that has the minimum value
x.argmin()

# Find the position in tensor that has the maximum value
x.argmax()

"""## Reshaping, stacking, squeezing and unsqueezing

* Reshaping - reshapes an input tensor to a defined shape
* View - Return a view of an input tensor of a certain shape but keep the same memory as the original tensor
* Stacking - combine multiple tensors along a dimension
* Squeeze - removes all "1" dimensions from a tensor
* Unsqueeze - add a "1" dimension to a target tensor
* Permute - Return a view of the input with dimension permuted in a certain way

"""

# Create a tensor
x = torch.arange(1.,10.)
x, x.shape

# Add an extra dimension
x_reshaped=x.reshape(9,1)
x_reshaped, x_reshaped.shape

# Change the view
z=x.view(1,9)
z, z.shape

# Changing z changes x because a view of a tensor shares the same memory as the original one
z[0,0]=5
z,x

# Stack tensors on top of each other